{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "249ad94e",
   "metadata": {},
   "source": [
    "# LangGraph Agent\n",
    "\n",
    "This notebook demonstrates how to build sophisticated RAG (Retrieval-Augmented Generation) systems using **LangGraph** - a powerful framework for building stateful, multi-actor applications with large language models.\n",
    "\n",
    "## What is LangGraph?\n",
    "LangGraph is a library for building stateful, multi-step applications with LLMs. It extends LangChain with graph-based workflows that can:\n",
    "- **Maintain State**: Preserve context across multiple steps\n",
    "- **Conditional Logic**: Make decisions based on intermediate results\n",
    "- **Tool Integration**: Seamlessly incorporate external tools and APIs\n",
    "- **Memory Management**: Handle conversation history and persistence\n",
    "\n",
    "## LangGraph vs Traditional RAG\n",
    "- **Traditional RAG**: Simple pipeline (Query â†’ Retrieve â†’ Generate)\n",
    "- **LangGraph RAG**: Stateful workflow with conditional paths, tool calls, and memory\n",
    "\n",
    "## What We'll Build\n",
    "We'll create two different RAG systems:\n",
    "1. **Custom LangGraph RAG**: A manually constructed graph with explicit state management\n",
    "2. **ReAct Agent**: A pre-built agent that uses Reasoning and Acting patterns\n",
    "\n",
    "## Key Concepts Covered\n",
    "1. **MessagesState**: LangGraph's built-in state for managing conversation history\n",
    "2. **Tools**: Functions the LLM can call to retrieve information\n",
    "3. **Conditional Edges**: Dynamic routing based on LLM decisions\n",
    "4. **Memory/Checkpointing**: Conversation persistence across sessions\n",
    "5. **Graph Visualization**: Understanding workflow structure\n",
    "6. **Multi-turn Conversations**: Handling follow-up questions with context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a7c788",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup and API Key Management\n",
    "\n",
    "This section handles the secure loading of API credentials for Azure OpenAI.\n",
    "\n",
    "### Your Task:\n",
    "Set up environment variables for Azure OpenAI API access.\n",
    "\n",
    "**Steps:**\n",
    "1. Import required modules:\n",
    "   - `load_dotenv` from `dotenv` (loads environment variables from .env file)\n",
    "   - `getpass` (for secure password input)\n",
    "   - `os` (for environment variable access)\n",
    "2. Call `load_dotenv()` to load environment variables from a `.env` file if present\n",
    "3. Check if `AZURE_OPENAI_API_KEY` exists in environment variables\n",
    "4. If not found, prompt the user securely: `os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter your Azure OpenAI API key: \")`\n",
    "\n",
    "**Security Best Practice:** \n",
    "- Never hardcode API keys in code\n",
    "- Use environment variables or secure prompts\n",
    "- Works both locally (with `.env` file) and in production (with system environment variables)\n",
    "\n",
    "**Expected Output:** No visible output, but the API key will be securely stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36fd59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import load_dotenv from dotenv, getpass, and os\n",
    "\n",
    "\n",
    "# TODO: Load environment variables from .env file\n",
    "\n",
    "\n",
    "# TODO: Check if AZURE_OPENAI_API_KEY exists, if not, prompt for it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d248830c",
   "metadata": {},
   "source": [
    "## Step 2: Initialize the Embedding Model\n",
    "\n",
    "**Embeddings** are the foundation of semantic search in RAG systems. They convert text into numerical vectors that capture meaning.\n",
    "\n",
    "### Your Task:\n",
    "Configure Azure OpenAI embeddings for converting text to vectors.\n",
    "\n",
    "**Steps:**\n",
    "1. Import `AzureOpenAIEmbeddings` from `langchain_openai`\n",
    "2. Create an embeddings instance with these parameters:\n",
    "   - `azure_endpoint=\"https://aoi-ext-eus-aiml-profx-01.openai.azure.com/\"`\n",
    "   - `api_key=os.environ[\"AZURE_OPENAI_API_KEY\"]`\n",
    "   - `model=\"text-embedding-ada-002\"`\n",
    "   - `api_version=\"2024-12-01-preview\"`\n",
    "\n",
    "### How Embeddings Work:\n",
    "- **Input**: Text strings (documents, queries)\n",
    "- **Output**: High-dimensional vectors (1536 dimensions for `text-embedding-ada-002`)\n",
    "- **Property**: Semantically similar text produces similar vectors\n",
    "\n",
    "**Expected Output:** No output, but the `embeddings` object will be ready to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36893a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import AzureOpenAIEmbeddings from langchain_openai\n",
    "\n",
    "\n",
    "# TODO: Create an AzureOpenAIEmbeddings instance with the required parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98fefe7",
   "metadata": {},
   "source": [
    "## Step 3: Initialize the Language Model (LLM)\n",
    "\n",
    "**Large Language Models (LLMs)** generate human-like text responses based on input prompts.\n",
    "\n",
    "### Your Task:\n",
    "Set up Azure Chat OpenAI for generating answers.\n",
    "\n",
    "**Steps:**\n",
    "1. Import `AzureChatOpenAI` from `langchain_openai`\n",
    "2. Create an LLM instance with these parameters:\n",
    "   - `azure_endpoint=\"https://aoi-ext-eus-aiml-profx-01.openai.azure.com/\"`\n",
    "   - `api_key=os.environ[\"AZURE_OPENAI_API_KEY\"]`\n",
    "   - `model=\"gpt-4o\"`\n",
    "   - `api_version=\"2024-12-01-preview\"`\n",
    "\n",
    "### Role in LangGraph:\n",
    "The LLM will:\n",
    "1. Process user queries\n",
    "2. Decide which tools to call\n",
    "3. Generate responses based on retrieved context\n",
    "4. Maintain conversation flow\n",
    "\n",
    "**Expected Output:** No output, but the `llm` object will be ready to generate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import AzureChatOpenAI from langchain_openai\n",
    "\n",
    "\n",
    "# TODO: Create an AzureChatOpenAI instance with the required parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eda928",
   "metadata": {},
   "source": [
    "## Step 4: Load and Prepare Document Data\n",
    "\n",
    "**Document Loading** is crucial for creating a knowledge base for our RAG system.\n",
    "\n",
    "### Your Task:\n",
    "Load documents from a web source and prepare them for vector storage.\n",
    "\n",
    "**Steps:**\n",
    "1. Import required classes:\n",
    "   - `WebBaseLoader` from `langchain_community.document_loaders`\n",
    "   - `RecursiveCharacterTextSplitter` from `langchain_text_splitters`\n",
    "2. Create a loader: `loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")`\n",
    "3. Load documents: `docs = loader.load()`\n",
    "4. Create a text splitter with `chunk_size=1000` and `chunk_overlap=200`\n",
    "5. Split the documents: `all_splits = text_splitter.split_documents(docs)`\n",
    "\n",
    "### Why Document Splitting?\n",
    "- Large documents exceed embedding model limits\n",
    "- Smaller chunks improve retrieval accuracy\n",
    "- Overlap ensures context isn't lost at chunk boundaries\n",
    "\n",
    "**Expected Output:** Information about the number of document chunks created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8511facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import WebBaseLoader and RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# TODO: Create a WebBaseLoader and load documents\n",
    "\n",
    "\n",
    "# TODO: Create a text splitter and split the documents\n",
    "\n",
    "\n",
    "# TODO: Print the number of document chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f563ad46",
   "metadata": {},
   "source": [
    "## Step 5: Create Vector Store with Document Embeddings\n",
    "\n",
    "**Vector Stores** enable semantic search by storing document embeddings and providing similarity search capabilities.\n",
    "\n",
    "### Your Task:\n",
    "Create a vector store and populate it with document embeddings.\n",
    "\n",
    "**Steps:**\n",
    "1. Import `InMemoryVectorStore` from `langchain_core.vectorstores`\n",
    "2. Create a vector store: `vector_store = InMemoryVectorStore(embeddings)`\n",
    "3. Add documents to the store: `vector_store.add_documents(all_splits)`\n",
    "\n",
    "### How Vector Stores Work:\n",
    "1. **Embedding Creation**: Each document chunk is converted to a vector using the embedding model\n",
    "2. **Storage**: Vectors are stored with their associated text and metadata\n",
    "3. **Retrieval**: Query vectors are compared against stored vectors to find similar content\n",
    "\n",
    "### InMemoryVectorStore Benefits:\n",
    "- Fast for development and small datasets\n",
    "- No external dependencies\n",
    "- Perfect for learning and prototyping\n",
    "\n",
    "**Expected Output:** Confirmation that documents have been indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef86021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import InMemoryVectorStore from langchain_core.vectorstores\n",
    "\n",
    "\n",
    "# TODO: Create an InMemoryVectorStore instance\n",
    "\n",
    "\n",
    "# TODO: Add documents to the vector store\n",
    "\n",
    "\n",
    "# TODO: Print confirmation message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7252763",
   "metadata": {},
   "source": [
    "## Step 6: Create the Retrieval Tool\n",
    "\n",
    "**Tools** in LangGraph are functions that the LLM can call to perform specific tasks. We'll create a retrieval tool that searches our vector store.\n",
    "\n",
    "### Your Task:\n",
    "Create a retrieval tool that the LLM can use to search for relevant documents.\n",
    "\n",
    "**Steps:**\n",
    "1. Define a retrieval function that:\n",
    "   - Takes a query string as input\n",
    "   - Uses `vector_store.similarity_search(query, k=3)` to find relevant documents\n",
    "   - Returns the concatenated content of retrieved documents\n",
    "2. Use the `@tool` decorator to convert the function into a LangChain tool\n",
    "3. Test the tool with a sample query\n",
    "\n",
    "### Tool Design Principles:\n",
    "- **Clear Purpose**: Each tool should have a specific, well-defined function\n",
    "- **Good Documentation**: Include docstrings that describe the tool's purpose and parameters\n",
    "- **Error Handling**: Handle cases where no relevant documents are found\n",
    "\n",
    "**Expected Output:** A working retrieval tool that can search the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import the tool decorator from langchain_core.tools\n",
    "\n",
    "\n",
    "# TODO: Define a retrieval function with the @tool decorator\n",
    "# The function should take a query parameter and return relevant documents\n",
    "\n",
    "\n",
    "# TODO: Test the retrieval tool with a sample query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bb4757",
   "metadata": {},
   "source": [
    "## Step 7: Set Up LangGraph State Management\n",
    "\n",
    "**State Management** is what makes LangGraph powerful. It allows the system to maintain context across multiple steps.\n",
    "\n",
    "### Your Task:\n",
    "Import and understand LangGraph's MessagesState for managing conversation history.\n",
    "\n",
    "**Steps:**\n",
    "1. Import `MessagesState` from `langgraph.graph`\n",
    "2. Import `SystemMessage` from `langchain_core.messages`\n",
    "\n",
    "### What is MessagesState?\n",
    "- **Built-in State**: Pre-defined state schema for chat applications\n",
    "- **Message History**: Automatically tracks conversation messages\n",
    "- **Persistence**: Can be saved and restored across sessions\n",
    "- **Flexible**: Can be extended with custom fields\n",
    "\n",
    "### Message Types:\n",
    "- **SystemMessage**: Sets the AI's role and behavior\n",
    "- **HumanMessage**: User inputs\n",
    "- **AIMessage**: AI responses\n",
    "- **ToolMessage**: Tool execution results\n",
    "\n",
    "**Expected Output:** No output, but required imports will be ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a8577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import MessagesState from langgraph.graph\n",
    "\n",
    "\n",
    "# TODO: Import SystemMessage from langchain_core.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec43c141",
   "metadata": {},
   "source": [
    "## Step 8: Build the LangGraph Workflow\n",
    "\n",
    "**LangGraph Workflows** define how the system processes information through a series of connected nodes.\n",
    "\n",
    "### Your Task:\n",
    "Create a LangGraph state graph and define the workflow nodes.\n",
    "\n",
    "**Steps:**\n",
    "1. Import required classes:\n",
    "   - `StateGraph` and `END` from `langgraph.graph`\n",
    "   - `ToolNode` from `langgraph.prebuilt`\n",
    "2. Create a StateGraph: `graph_builder = StateGraph(MessagesState)`\n",
    "3. Create a tools list containing your retrieval tool\n",
    "4. Create a ToolNode: `tools = ToolNode([retrieve])`\n",
    "5. Bind tools to the LLM: `llm = llm.bind_tools([retrieve])`\n",
    "\n",
    "### Graph Components:\n",
    "- **Nodes**: Individual processing steps (chatbot, tools)\n",
    "- **Edges**: Connections between nodes\n",
    "- **State**: Shared data that flows through the graph\n",
    "- **Conditional Logic**: Dynamic routing based on conditions\n",
    "\n",
    "**Expected Output:** A configured graph builder ready for node definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6bc806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import StateGraph, END from langgraph.graph and ToolNode from langgraph.prebuilt\n",
    "\n",
    "\n",
    "# TODO: Create a StateGraph with MessagesState\n",
    "\n",
    "\n",
    "# TODO: Create a tools list and ToolNode\n",
    "\n",
    "\n",
    "# TODO: Bind tools to the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d0d4d",
   "metadata": {},
   "source": [
    "## Step 9: Define Graph Nodes and Logic\n",
    "\n",
    "**Graph Nodes** are the processing units in our LangGraph workflow. Each node performs a specific function.\n",
    "\n",
    "### Your Task:\n",
    "Define the chatbot node and tool routing logic.\n",
    "\n",
    "**Steps:**\n",
    "1. Define a `chatbot` function that:\n",
    "   - Takes the current state as input\n",
    "   - Adds a system message if this is the first interaction\n",
    "   - Invokes the LLM with the current messages\n",
    "   - Returns the response\n",
    "\n",
    "2. Define a `route_tools` function that:\n",
    "   - Checks if the last AI message has tool calls\n",
    "   - Returns \"tools\" if tools are called, otherwise END\n",
    "\n",
    "3. Add nodes to the graph:\n",
    "   - `graph_builder.add_node(\"chatbot\", chatbot)`\n",
    "   - `graph_builder.add_node(\"tools\", tools)`\n",
    "\n",
    "4. Add edges:\n",
    "   - `graph_builder.add_conditional_edge(\"chatbot\", route_tools, {\"tools\": \"tools\", END: END})`\n",
    "   - `graph_builder.add_edge(\"tools\", \"chatbot\")`\n",
    "   - `graph_builder.set_entry_point(\"chatbot\")`\n",
    "\n",
    "**Expected Output:** A fully configured graph ready for compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c95492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the chatbot function\n",
    "def chatbot(state: MessagesState):\n",
    "    # TODO: Add system message if no messages exist\n",
    "    \n",
    "    # TODO: Invoke the LLM and return the response\n",
    "    pass\n",
    "\n",
    "# TODO: Define the route_tools function\n",
    "def route_tools(state: MessagesState):\n",
    "    # TODO: Check if the last message has tool calls\n",
    "    # Return \"tools\" if tools are called, otherwise END\n",
    "    pass\n",
    "\n",
    "# TODO: Add nodes to the graph\n",
    "\n",
    "\n",
    "# TODO: Add edges to connect the nodes\n",
    "\n",
    "\n",
    "# TODO: Set the entry point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e6019c",
   "metadata": {},
   "source": [
    "## Step 10: Compile and Test the Graph\n",
    "\n",
    "**Graph Compilation** converts your graph definition into an executable workflow.\n",
    "\n",
    "### Your Task:\n",
    "Compile the graph and test it with a simple query.\n",
    "\n",
    "**Steps:**\n",
    "1. Compile the graph: `graph = graph_builder.compile()`\n",
    "2. Create a test configuration dictionary\n",
    "3. Test with a simple query using `graph.invoke()`\n",
    "4. Print the response\n",
    "\n",
    "### Graph Compilation Process:\n",
    "- **Validation**: Checks that all nodes and edges are properly defined\n",
    "- **Optimization**: Optimizes the execution path\n",
    "- **Execution Ready**: Creates a runnable graph instance\n",
    "\n",
    "**Expected Output:** A working LangGraph that can answer questions using RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5ab61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile the graph\n",
    "\n",
    "\n",
    "# TODO: Create a test configuration\n",
    "\n",
    "\n",
    "# TODO: Test the graph with a simple query\n",
    "\n",
    "\n",
    "# TODO: Print the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d17440c",
   "metadata": {},
   "source": [
    "## Step 11: Visualize the Graph Structure\n",
    "\n",
    "**Graph Visualization** helps understand the workflow structure and debug issues.\n",
    "\n",
    "### Your Task:\n",
    "Generate a visual representation of your LangGraph workflow.\n",
    "\n",
    "**Steps:**\n",
    "1. Use `graph.get_graph().draw_mermaid_png()` to generate a diagram\n",
    "2. Display the diagram using appropriate visualization methods\n",
    "\n",
    "### Understanding the Diagram:\n",
    "- **Nodes**: Rectangular boxes representing processing steps\n",
    "- **Edges**: Arrows showing the flow between nodes\n",
    "- **Conditional Edges**: Diamond shapes indicating decision points\n",
    "- **Entry/Exit Points**: Special nodes marking start and end\n",
    "\n",
    "**Expected Output:** A visual diagram of your LangGraph workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65acf31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate and display the graph visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f2da2d",
   "metadata": {},
   "source": [
    "## Step 12: Test Complex Queries\n",
    "\n",
    "**Complex Queries** test the system's ability to handle multi-step reasoning and tool usage.\n",
    "\n",
    "### Your Task:\n",
    "Test the system with a more complex question that requires retrieval.\n",
    "\n",
    "**Expected Output:** A comprehensive answer based on retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test with a complex query about agents\n",
    "input_message = \"What are the key components of an LLM-powered agent according to the document?\"\n",
    "\n",
    "# TODO: Invoke the graph and print the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a218f09b",
   "metadata": {},
   "source": [
    "## Step 13: Add Memory and Persistence\n",
    "\n",
    "**Memory and Persistence** allow the system to maintain conversation context across multiple interactions.\n",
    "\n",
    "### Your Task:\n",
    "Add memory capabilities to enable multi-turn conversations.\n",
    "\n",
    "**Steps:**\n",
    "1. Import `MemorySaver` from `langgraph.checkpoint.memory`\n",
    "2. Create a memory instance: `memory = MemorySaver()`\n",
    "3. Recompile the graph with memory: `agent_executor = graph_builder.compile(checkpointer=memory)`\n",
    "4. Create a config with a thread ID for conversation tracking\n",
    "\n",
    "### Benefits of Memory:\n",
    "- **Context Continuity**: Maintains conversation history\n",
    "- **Follow-up Questions**: Can reference previous exchanges\n",
    "- **Session Management**: Different threads for different conversations\n",
    "- **Persistence**: Conversations can be resumed later\n",
    "\n",
    "**Expected Output:** A memory-enabled agent ready for multi-turn conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245163d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import MemorySaver from langgraph.checkpoint.memory\n",
    "\n",
    "\n",
    "# TODO: Create a memory instance and recompile the graph\n",
    "\n",
    "\n",
    "# TODO: Create a config with thread ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e008da",
   "metadata": {},
   "source": [
    "## Step 14: Test Multi-turn Conversations\n",
    "\n",
    "**Multi-turn Conversations** demonstrate the system's ability to maintain context across multiple exchanges.\n",
    "\n",
    "### Your Task:\n",
    "Test the memory-enabled system with follow-up questions.\n",
    "\n",
    "**Steps:**\n",
    "1. Ask an initial question\n",
    "2. Ask a follow-up question that references the previous response\n",
    "3. Observe how the system maintains context\n",
    "\n",
    "**Expected Output:** Contextually aware responses that reference previous parts of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f33dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test the first question\n",
    "input_message = \"What is retrieval-augmented generation?\"\n",
    "\n",
    "# TODO: Invoke the agent and print the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07c8c47",
   "metadata": {},
   "source": [
    "## Step 15: Ask Follow-up Questions\n",
    "\n",
    "### Your Task:\n",
    "Ask a follow-up question to test conversation memory.\n",
    "\n",
    "**Expected Output:** A response that references the previous conversation context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e81af83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Ask a follow-up question\n",
    "input_message_2 = \"What are the advantages of this approach?\"\n",
    "\n",
    "# TODO: Invoke the agent and print the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e28b5",
   "metadata": {},
   "source": [
    "## Step 16: Build a ReAct Agent (Alternative Approach)\n",
    "\n",
    "**ReAct Agents** use a pre-built pattern for Reasoning and Acting. They automatically decide when and how to use tools.\n",
    "\n",
    "### Your Task:\n",
    "Create a ReAct agent using LangGraph's built-in functionality.\n",
    "\n",
    "**Steps:**\n",
    "1. Import `create_react_agent` from `langgraph.prebuilt`\n",
    "2. Create a ReAct agent with the LLM and tools list\n",
    "3. Test the agent with the same queries\n",
    "\n",
    "### ReAct vs Custom Graph:\n",
    "- **ReAct**: Pre-built, standardized reasoning pattern\n",
    "- **Custom**: Full control over workflow and logic\n",
    "- **Use ReAct when**: You want a standard agent pattern\n",
    "- **Use Custom when**: You need specific workflow logic\n",
    "\n",
    "**Expected Output:** A working ReAct agent that performs similar functions to your custom graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9389ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import create_react_agent from langgraph.prebuilt\n",
    "\n",
    "\n",
    "# TODO: Create a ReAct agent\n",
    "\n",
    "\n",
    "# TODO: Test the ReAct agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f164a3a4",
   "metadata": {},
   "source": [
    "## Step 17: Compare Approaches\n",
    "\n",
    "**Approach Comparison** helps understand when to use different LangGraph patterns.\n",
    "\n",
    "### Your Task:\n",
    "Test both the custom graph and ReAct agent with the same query and compare results.\n",
    "\n",
    "### Key Differences:\n",
    "- **Implementation Complexity**: Custom requires more code, ReAct is simpler\n",
    "- **Flexibility**: Custom allows precise control, ReAct follows standard patterns\n",
    "- **Debugging**: Custom easier to debug, ReAct more opaque\n",
    "- **Performance**: Both should perform similarly for basic RAG tasks\n",
    "\n",
    "**Expected Output:** Insights into which approach works better for different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d72d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test both approaches with the same query and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1614ab6e",
   "metadata": {},
   "source": [
    "## Step 18: Visualize the ReAct Agent\n",
    "\n",
    "### Your Task:\n",
    "Visualize the ReAct agent structure to understand its internal workflow.\n",
    "\n",
    "**Expected Output:** A diagram showing the ReAct agent's internal structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35acd925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize the ReAct agent structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745de76a",
   "metadata": {},
   "source": [
    "## Step 19: Stream Responses for Better UX\n",
    "\n",
    "**Streaming Responses** provide a better user experience by showing incremental progress.\n",
    "\n",
    "### Your Task:\n",
    "Implement streaming to see the agent's responses as they're generated.\n",
    "\n",
    "**Steps:**\n",
    "1. Use `agent_executor.stream()` instead of `invoke()`\n",
    "2. Iterate through the streaming events\n",
    "3. Print each step as it happens\n",
    "\n",
    "### Benefits of Streaming:\n",
    "- **Real-time Feedback**: Users see progress immediately\n",
    "- **Better UX**: No waiting for complete responses\n",
    "- **Debugging**: Can see each step of the process\n",
    "- **Transparency**: Users understand what the system is doing\n",
    "\n",
    "**Expected Output:** Step-by-step streaming of the agent's reasoning and responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe9a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement streaming responses\n",
    "input_message = \"Explain the concept of autonomous agents and their capabilities\"\n",
    "\n",
    "# TODO: Stream the response and print each event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bae7c3",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Congratulations!\n",
    "\n",
    "You've successfully built two different types of RAG systems using LangGraph:\n",
    "\n",
    "### What You've Accomplished:\n",
    "1. âœ… **Custom LangGraph RAG**: Built a sophisticated workflow with explicit state management\n",
    "2. âœ… **ReAct Agent**: Used pre-built patterns for rapid development\n",
    "3. âœ… **Memory Integration**: Added conversation persistence across multiple turns\n",
    "4. âœ… **Tool Integration**: Created and used custom retrieval tools\n",
    "5. âœ… **Graph Visualization**: Generated visual representations of workflows\n",
    "6. âœ… **Streaming Responses**: Implemented real-time response streaming\n",
    "\n",
    "### Key Takeaways:\n",
    "- **LangGraph Power**: Enables stateful, multi-step AI applications\n",
    "- **Flexibility**: Choice between custom graphs and pre-built agents\n",
    "- **Memory Management**: Crucial for conversational AI systems\n",
    "- **Tool Integration**: Seamless connection of LLMs with external data sources\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different document sources\n",
    "- Add more sophisticated tools\n",
    "- Implement error handling and validation\n",
    "- Deploy your system to production\n",
    "\n",
    "Great work on mastering advanced RAG with LangGraph! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
