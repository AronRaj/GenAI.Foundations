{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdfca7c6",
   "metadata": {},
   "source": [
    "# LangGraph Agent\n",
    "\n",
    "This notebook demonstrates how to build sophisticated RAG (Retrieval-Augmented Generation) systems using **LangGraph** - a powerful framework for building stateful, multi-actor applications with large language models.\n",
    "\n",
    "## What is LangGraph?\n",
    "LangGraph is a library for building stateful, multi-step applications with LLMs. It extends LangChain with graph-based workflows that can:\n",
    "- **Maintain State**: Preserve context across multiple steps\n",
    "- **Conditional Logic**: Make decisions based on intermediate results\n",
    "- **Tool Integration**: Seamlessly incorporate external tools and APIs\n",
    "- **Memory Management**: Handle conversation history and persistence\n",
    "\n",
    "## LangGraph vs Traditional RAG\n",
    "- **Traditional RAG**: Simple pipeline (Query → Retrieve → Generate)\n",
    "- **LangGraph RAG**: Stateful workflow with conditional paths, tool calls, and memory\n",
    "\n",
    "## What We'll Build\n",
    "We'll create two different RAG systems:\n",
    "1. **Custom LangGraph RAG**: A manually constructed graph with explicit state management\n",
    "2. **ReAct Agent**: A pre-built agent that uses Reasoning and Acting patterns\n",
    "\n",
    "## Key Concepts Covered\n",
    "1. **MessagesState**: LangGraph's built-in state for managing conversation history\n",
    "2. **Tools**: Functions the LLM can call to retrieve information\n",
    "3. **Conditional Edges**: Dynamic routing based on LLM decisions\n",
    "4. **Memory/Checkpointing**: Conversation persistence across sessions\n",
    "5. **Graph Visualization**: Understanding workflow structure\n",
    "6. **Multi-turn Conversations**: Handling follow-up questions with context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca13041",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup and API Key Management\n",
    "\n",
    "This section handles the secure loading of API credentials for Azure OpenAI:\n",
    "\n",
    "### Key Components:\n",
    "- **`load_dotenv()`**: Loads environment variables from a `.env` file if it exists in the project directory\n",
    "- **Security Best Practice**: Checks if the API key is already set in environment variables before prompting\n",
    "- **Interactive Prompt**: If the key isn't found, securely prompts the user to enter it (input will be hidden)\n",
    "\n",
    "### Environment Variable Strategy:\n",
    "- **Development**: Use a `.env` file in your project root\n",
    "- **Production**: Set system environment variables\n",
    "- **Security**: Never hardcode API keys in your source code\n",
    "\n",
    "This approach ensures your credentials are handled securely across different deployment environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ec337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# Load environment variables from a .env file if present. This helps in local dev where env vars aren't set.\n",
    "load_dotenv()\n",
    "\n",
    "# Prompt for API key only if not present in environment variables after loading .env\n",
    "if not os.environ.get(\"AZURE_OPENAI_API_KEY\"):\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter your Azure OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f21a5",
   "metadata": {},
   "source": [
    "## Step 2: Initialize the Embedding Model\n",
    "\n",
    "**Embeddings** are the foundation of semantic search in RAG systems. They convert text into numerical vectors that capture meaning.\n",
    "\n",
    "### How Embeddings Work:\n",
    "- **Input**: Text strings (documents, queries)\n",
    "- **Output**: High-dimensional vectors (1536 dimensions for `text-embedding-ada-002`)\n",
    "- **Property**: Semantically similar text produces similar vectors\n",
    "\n",
    "### Configuration Details:\n",
    "- **`text-embedding-ada-002`**: Azure OpenAI's powerful embedding model\n",
    "- **Vector Dimensions**: 1536-dimensional vectors that capture rich semantic meaning\n",
    "- **Use Cases**: Document indexing, similarity search, semantic retrieval\n",
    "\n",
    "### Role in LangGraph RAG:\n",
    "- **Document Indexing**: Convert document chunks to vectors for storage\n",
    "- **Query Processing**: Convert user questions to vectors for similarity search\n",
    "- **Retrieval**: Find relevant documents by comparing vector similarities\n",
    "\n",
    "The embedding model enables **semantic search** - finding documents by meaning rather than just keyword matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53aebb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=\"https://aoi-ext-eus-aiml-profx-01.openai.azure.com/\",\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    api_version=\"2024-12-01-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b25fd",
   "metadata": {},
   "source": [
    "## Step 3: Initialize the Large Language Model (LLM)\n",
    "\n",
    "**Large Language Models** are the reasoning and generation component of our RAG system.\n",
    "\n",
    "### Model Configuration:\n",
    "- **`gpt-4o`**: GPT-4 Optimized - a powerful chat-optimized model\n",
    "- **Chat Interface**: Designed for conversational interactions\n",
    "- **API Version**: Latest version for best performance and features\n",
    "\n",
    "### Role in LangGraph:\n",
    "Unlike traditional RAG where the LLM only generates final answers, in LangGraph the LLM serves multiple roles:\n",
    "1. **Decision Making**: Decides whether to call tools or respond directly\n",
    "2. **Tool Selection**: Chooses which tools to use based on the query\n",
    "3. **Response Generation**: Creates final answers using retrieved context\n",
    "4. **Conversation Management**: Maintains multi-turn dialogue context\n",
    "\n",
    "### LangGraph Enhancement:\n",
    "LangGraph allows the LLM to be more autonomous - it can decide its own workflow rather than following a fixed pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fae6501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://aoi-ext-eus-aiml-profx-01.openai.azure.com/\",\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    model=\"gpt-4o\",\n",
    "    api_version=\"2024-12-01-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10031ac4",
   "metadata": {},
   "source": [
    "## Step 4: Create the Vector Store\n",
    "\n",
    "**Vector Stores** are databases optimized for storing and searching high-dimensional vectors (embeddings).\n",
    "\n",
    "### What is `InMemoryVectorStore`?\n",
    "- **Storage**: Keeps all vectors in RAM for fast access\n",
    "- **Similarity Search**: Uses cosine similarity to find related documents\n",
    "- **Development Tool**: Perfect for prototyping and small datasets\n",
    "- **Automatic Integration**: Uses the embedding model we configured earlier\n",
    "\n",
    "### How Vector Similarity Works:\n",
    "1. **Document Storage**: Text chunks → Embeddings → Vector database\n",
    "2. **Query Processing**: User question → Embedding → Query vector\n",
    "3. **Similarity Search**: Compare query vector with document vectors\n",
    "4. **Retrieval**: Return most similar documents based on cosine distance\n",
    "\n",
    "### Production Considerations:\n",
    "For large-scale applications, consider persistent vector stores like:\n",
    "- **Chroma**: Open-source vector database\n",
    "- **Pinecone**: Managed vector database service\n",
    "- **Azure AI Search**: Azure's vector search service\n",
    "- **Qdrant**: High-performance vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5dccceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff20f827",
   "metadata": {},
   "source": [
    "## Step 5: Load and Process Documents\n",
    "\n",
    "**Document Loading and Chunking** - Building the knowledge base for our RAG system.\n",
    "\n",
    "### Document Loading Process:\n",
    "- **`WebBaseLoader`**: Fetches content from web URLs\n",
    "- **BeautifulSoup Integration**: Parses HTML and extracts relevant content\n",
    "- **Content Filtering**: Uses `SoupStrainer` to keep only meaningful content (post-title, post-header, post-content)\n",
    "\n",
    "### Why Filter HTML Content?\n",
    "- **Noise Reduction**: Removes navigation, ads, footers, and sidebar content\n",
    "- **Quality Improvement**: Focuses on the main article content\n",
    "- **Better Embeddings**: Cleaner text produces more accurate vector representations\n",
    "\n",
    "### Text Chunking Strategy:\n",
    "- **Chunk Size**: 1000 characters per chunk (optimal for embeddings)\n",
    "- **Overlap**: 200 characters overlap between chunks to maintain context\n",
    "- **Recursive Splitting**: Splits on natural boundaries (paragraphs, sentences, words)\n",
    "\n",
    "### Why Split Documents?\n",
    "1. **Embedding Quality**: Smaller chunks create more focused, precise embeddings\n",
    "2. **Retrieval Precision**: Can retrieve specific relevant sections instead of entire documents\n",
    "3. **Context Window Management**: Fits within LLM input limits\n",
    "4. **Memory Efficiency**: Reduces memory usage for large documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6dd726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b8511",
   "metadata": {},
   "source": [
    "## Step 6: Index Documents in Vector Store\n",
    "\n",
    "**Document Indexing** - Converting text chunks to searchable vectors.\n",
    "\n",
    "### The Indexing Process:\n",
    "1. **Embedding Generation**: Each document chunk is sent to the embedding model\n",
    "2. **Vector Creation**: The model returns a 1536-dimensional vector for each chunk\n",
    "3. **Storage**: Both the vector and original text are stored in the vector database\n",
    "4. **Indexing**: Vectors are organized for fast similarity search\n",
    "\n",
    "### What Happens Under the Hood:\n",
    "- Document chunks are processed in batches for efficiency\n",
    "- Each chunk gets a unique ID for later retrieval\n",
    "- The vector store builds an index structure for fast search\n",
    "- Original metadata (source, chunk position) is preserved\n",
    "\n",
    "### Ready for Retrieval:\n",
    "Once indexed, the system can:\n",
    "- Accept user queries in natural language\n",
    "- Convert queries to embeddings\n",
    "- Find semantically similar document chunks\n",
    "- Return relevant context for answer generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "138d3632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0669846b",
   "metadata": {},
   "source": [
    "## Step 7: Initialize LangGraph with MessagesState\n",
    "\n",
    "**LangGraph Introduction** - Building stateful, multi-step workflows with LLMs.\n",
    "\n",
    "### What is MessagesState?\n",
    "`MessagesState` is LangGraph's built-in state schema that automatically manages conversation history:\n",
    "- **Message History**: Automatically tracks all messages (human, AI, system, tool)\n",
    "- **State Persistence**: Maintains context across multiple steps in the workflow\n",
    "- **Type Safety**: Ensures proper message formatting and validation\n",
    "- **Automatic Appending**: New messages are appended to the conversation history\n",
    "\n",
    "### StateGraph vs Traditional Chains:\n",
    "- **Traditional Chain**: Linear pipeline (A → B → C)\n",
    "- **StateGraph**: Flexible workflow with conditional paths and loops\n",
    "- **State Management**: Automatic state passing between nodes\n",
    "- **Decision Making**: LLM can choose different paths based on context\n",
    "\n",
    "### Key Advantages:\n",
    "1. **Flexibility**: Dynamic routing based on LLM decisions\n",
    "2. **Memory**: Persistent conversation context\n",
    "3. **Tool Integration**: Seamless tool calling and response handling\n",
    "4. **Debugging**: Visual workflow representation and step-by-step execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7fa327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1639d53f",
   "metadata": {},
   "source": [
    "## Step 8: Define the Retrieval Tool\n",
    "\n",
    "**Tools** in LangGraph are functions that the LLM can call to perform specific tasks.\n",
    "\n",
    "### The `@tool` Decorator:\n",
    "- **Function to Tool**: Converts a Python function into an LLM-callable tool\n",
    "- **`response_format=\"content_and_artifact\"`**: Returns both user-readable content and structured data\n",
    "- **Automatic Schema**: LangGraph generates the tool schema from function signature and docstring\n",
    "\n",
    "### How the Retrieve Tool Works:\n",
    "1. **Input**: Takes a query string from the LLM\n",
    "2. **Search**: Performs similarity search in the vector store (k=2 returns top 2 matches)\n",
    "3. **Format**: Structures the results with source metadata and content\n",
    "4. **Return**: Provides both formatted text (for LLM) and raw documents (for artifacts)\n",
    "\n",
    "### Tool Calling Flow:\n",
    "1. **LLM Decision**: The LLM decides if it needs to call the retrieve tool\n",
    "2. **Tool Execution**: LangGraph executes the tool with the LLM's parameters\n",
    "3. **Result Integration**: Tool results are added to the conversation state\n",
    "4. **LLM Processing**: The LLM uses the retrieved context to generate a response\n",
    "\n",
    "### Benefits of Tool-based Retrieval:\n",
    "- **Dynamic**: LLM decides when to retrieve based on the query\n",
    "- **Flexible**: Can call tools multiple times if needed\n",
    "- **Transparent**: Clear separation between retrieval and generation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e059b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60129799",
   "metadata": {},
   "source": [
    "## Step 9: Define Graph Nodes - Query, Tool Execution, and Generation\n",
    "\n",
    "**The Three-Node Workflow** - The core components of our LangGraph RAG system.\n",
    "\n",
    "### Node 1: `query_or_respond`\n",
    "**Purpose**: LLM decides whether to call tools or respond directly\n",
    "- **Tool Binding**: `llm.bind_tools([retrieve])` gives the LLM access to the retrieve tool\n",
    "- **Decision Making**: LLM analyzes the query and decides if retrieval is needed\n",
    "- **Tool Calls**: If retrieval is needed, generates a tool call message\n",
    "- **Direct Response**: If no retrieval needed, responds directly\n",
    "\n",
    "### Node 2: `tools` (ToolNode)\n",
    "**Purpose**: Executes tool calls and returns results\n",
    "- **Tool Execution**: Runs the retrieve function with LLM-provided parameters\n",
    "- **Result Formatting**: Converts tool outputs into ToolMessages\n",
    "- **State Update**: Adds tool results to the conversation state\n",
    "\n",
    "### Node 3: `generate`\n",
    "**Purpose**: Creates final response using retrieved context\n",
    "- **Context Extraction**: Gathers all recent ToolMessages from the conversation\n",
    "- **Prompt Construction**: Builds a system prompt with retrieved context\n",
    "- **Response Generation**: LLM generates answer based on context and conversation history\n",
    "- **Quality Control**: Includes instructions for concise, grounded responses\n",
    "\n",
    "### The LangGraph Advantage:\n",
    "Unlike traditional RAG pipelines, this workflow is **dynamic**:\n",
    "- LLM can skip retrieval for simple questions\n",
    "- Can call retrieval multiple times if needed\n",
    "- Maintains full conversation context throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed819044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07463ada",
   "metadata": {},
   "source": [
    "## Step 10: Build the Graph Workflow\n",
    "\n",
    "**Graph Construction** - Connecting nodes with conditional logic and edges.\n",
    "\n",
    "### Adding Nodes:\n",
    "- **`query_or_respond`**: Entry point that decides on tool usage\n",
    "- **`tools`**: Executes the retrieve tool when called\n",
    "- **`generate`**: Creates the final response with context\n",
    "\n",
    "### Defining the Flow:\n",
    "1. **Entry Point**: `set_entry_point(\"query_or_respond\")` - Start with LLM decision\n",
    "2. **Conditional Edge**: `tools_condition` examines if the LLM made tool calls\n",
    "   - **If tool calls exist**: Route to \"tools\" node\n",
    "   - **If no tool calls**: Go directly to END (skip retrieval)\n",
    "3. **Sequential Edges**: \n",
    "   - `tools → generate`: After retrieval, generate response\n",
    "   - `generate → END`: Finish after response generation\n",
    "\n",
    "### The Magic of `tools_condition`:\n",
    "This pre-built function automatically:\n",
    "- Checks the last AI message for tool calls\n",
    "- Routes to appropriate next step\n",
    "- Handles the decision logic transparently\n",
    "\n",
    "### Workflow Flexibility:\n",
    "- **Simple Questions**: query_or_respond → END (no retrieval)\n",
    "- **Complex Questions**: query_or_respond → tools → generate → END\n",
    "- **Dynamic Routing**: LLM controls its own workflow based on query complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d3c30a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7b9065",
   "metadata": {},
   "source": [
    "## Step 11: Visualize the Graph Workflow\n",
    "\n",
    "**Workflow Visualization** - Understanding the graph structure through diagrams.\n",
    "\n",
    "### Mermaid Diagram Generation:\n",
    "LangGraph automatically generates visual representations of your workflow:\n",
    "- **Nodes**: Circular shapes representing each function/step\n",
    "- **Edges**: Arrows showing the flow direction\n",
    "- **Conditional Logic**: Diamond shapes for decision points\n",
    "- **Entry/Exit Points**: Special markers for start and end\n",
    "\n",
    "### Benefits of Visualization:\n",
    "1. **Debugging**: Quickly identify workflow issues\n",
    "2. **Documentation**: Clear visual communication of system design\n",
    "3. **Optimization**: Spot unnecessary complexity or missing paths\n",
    "4. **Team Collaboration**: Shared understanding of system architecture\n",
    "\n",
    "### What You'll See:\n",
    "- **query_or_respond**: Starting point with conditional output\n",
    "- **tools**: Tool execution node\n",
    "- **generate**: Response generation node\n",
    "- **Conditional edges**: Dynamic routing based on LLM decisions\n",
    "\n",
    "This visual representation makes complex workflows much easier to understand and maintain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a8fed12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5f7483",
   "metadata": {},
   "source": [
    "## Step 12: Test Simple Greeting\n",
    "\n",
    "**Simple Query Test** - Testing the system with a basic greeting.\n",
    "\n",
    "### Expected Behavior:\n",
    "- **No Tool Calls**: The LLM should recognize this as a simple greeting\n",
    "- **Direct Response**: Should respond without needing retrieval\n",
    "- **Workflow Path**: query_or_respond → END (skipping tools and generate)\n",
    "\n",
    "### Why This is Important:\n",
    "- **Efficiency**: Simple queries don't need expensive retrieval operations\n",
    "- **Performance**: Faster response times for basic interactions\n",
    "- **Intelligence**: Demonstrates the LLM's ability to route appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7dd67e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Hello\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a869bc67",
   "metadata": {},
   "source": [
    "## Step 13: Test with Knowledge Query\n",
    "\n",
    "**RAG Test** - Testing the complete retrieval-augmented generation workflow.\n",
    "\n",
    "### Complex Query:\n",
    "\"What is Task Decomposition?\" - A question that requires knowledge retrieval.\n",
    "\n",
    "### Expected Workflow:\n",
    "1. **query_or_respond**: LLM recognizes this needs domain knowledge\n",
    "2. **Tool Call**: Generates a call to the retrieve tool with the query\n",
    "3. **tools**: Executes similarity search and returns relevant documents\n",
    "4. **generate**: Uses retrieved context to create an informed response\n",
    "\n",
    "### Full RAG Pipeline:\n",
    "- **Question Analysis**: LLM determines retrieval is needed\n",
    "- **Context Retrieval**: Vector search finds relevant document chunks\n",
    "- **Response Generation**: LLM synthesizes answer from retrieved context\n",
    "- **Grounded Answer**: Response is based on actual document content, not just LLM training\n",
    "\n",
    "### Observation Points:\n",
    "- **Tool Call Message**: Shows the LLM's decision to use retrieval\n",
    "- **Tool Response**: Displays the retrieved document chunks\n",
    "- **Final Answer**: Grounded response based on retrieved context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da704434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Task Decomposition?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_ttpsMVia2OXeF2sKKm3iM0cN)\n",
      " Call ID: call_ttpsMVia2OXeF2sKKm3iM0cN\n",
      "  Args:\n",
      "    query: Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition is the process of breaking down a complex task into smaller, manageable subtasks or steps. Techniques like Chain of Thought (CoT) prompt models to \"think step by step,\" while Tree of Thoughts explores multiple reasoning paths at each step. Decomposition can be guided by prompts, task-specific instructions, or human inputs.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"What is Task Decomposition?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850863ad",
   "metadata": {},
   "source": [
    "## Step 14: Add Memory and Persistence\n",
    "\n",
    "**Conversation Memory** - Enabling multi-turn conversations with context persistence.\n",
    "\n",
    "### What is MemorySaver?\n",
    "- **In-Memory Checkpointing**: Stores conversation state in RAM\n",
    "- **Thread-based Conversations**: Each conversation has a unique thread ID\n",
    "- **State Persistence**: Maintains full message history across interactions\n",
    "- **Automatic Management**: LangGraph handles state saving and loading\n",
    "\n",
    "### How Checkpointing Works:\n",
    "1. **State Snapshots**: After each step, the complete state is saved\n",
    "2. **Thread Isolation**: Each conversation thread is independent\n",
    "3. **Resume Capability**: Can continue conversations from any point\n",
    "4. **History Access**: Full conversation context is available to the LLM\n",
    "\n",
    "### Configuration:\n",
    "- **Thread ID**: `\"abc123\"` - unique identifier for this conversation\n",
    "- **Configurable**: Can be set per conversation for isolation\n",
    "- **Persistent Memory**: The graph now remembers previous exchanges\n",
    "\n",
    "### Benefits:\n",
    "- **Context Continuity**: LLM remembers previous questions and answers\n",
    "- **Follow-up Questions**: Can reference earlier parts of the conversation\n",
    "- **Session Management**: Multiple independent conversation threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea9fd251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# Specify an ID for the thread\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6009e01",
   "metadata": {},
   "source": [
    "## Step 15: Test with Persistent Memory\n",
    "\n",
    "**Memory in Action** - Testing conversation persistence with the same query.\n",
    "\n",
    "### Thread-based Memory:\n",
    "- **Same Thread ID**: `\"abc123\"` - continues the previous conversation\n",
    "- **Full Context**: The system remembers all previous interactions\n",
    "- **State Continuity**: Complete message history is maintained\n",
    "\n",
    "### What This Demonstrates:\n",
    "- **Persistence**: Even though we're asking the same question, the system maintains context\n",
    "- **Memory Management**: Previous messages remain accessible\n",
    "- **State Isolation**: This thread is separate from other conversations\n",
    "- **Conversation Flow**: Natural continuation of the dialogue\n",
    "\n",
    "### Memory Benefits:\n",
    "1. **Context Awareness**: LLM can reference previous exchanges\n",
    "2. **Conversation Continuity**: Maintains natural dialogue flow\n",
    "3. **Session Management**: Each thread maintains independent state\n",
    "4. **Debugging**: Can trace full conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e42581be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Task Decomposition?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_gKWMZqx4P1s3PS1dvtKbVNKN)\n",
      " Call ID: call_gKWMZqx4P1s3PS1dvtKbVNKN\n",
      "  Args:\n",
      "    query: What is Task Decomposition?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition is the process of breaking down a complex task into smaller, simpler steps or subgoals to make it more manageable. Techniques like Chain of Thought (CoT) and Tree of Thoughts (ToT) are commonly used to achieve this by guiding reasoning step-by-step or exploring multiple possibilities. It can be done via prompting a model, using task-specific instructions, or with human inputs.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"What is Task Decomposition?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936e07fc",
   "metadata": {},
   "source": [
    "## Step 16: Test Follow-up Questions\n",
    "\n",
    "**Multi-turn Conversation** - Demonstrating contextual follow-up questions.\n",
    "\n",
    "### The Follow-up Query:\n",
    "\"Can you look up some common ways of doing it?\" - Notice the ambiguous reference \"it\"\n",
    "\n",
    "### Context Resolution:\n",
    "- **Pronoun Reference**: \"it\" refers to \"Task Decomposition\" from the previous exchange\n",
    "- **Conversation Memory**: The system remembers the previous topic\n",
    "- **Contextual Understanding**: LLM can resolve references from conversation history\n",
    "- **Intelligent Retrieval**: May retrieve additional relevant information\n",
    "\n",
    "### What Makes This Powerful:\n",
    "1. **Natural Dialogue**: Users can speak naturally with pronouns and references\n",
    "2. **Context Continuity**: No need to repeat the full question\n",
    "3. **Progressive Discovery**: Build knowledge through a series of related questions\n",
    "4. **Memory Integration**: Previous answers inform current responses\n",
    "\n",
    "### Expected Behavior:\n",
    "- The system should understand \"it\" refers to Task Decomposition\n",
    "- May perform additional retrieval for \"common ways\" or \"methods\"\n",
    "- Response should build on the previous conversation context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a622fc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up some common ways of doing it?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_F2q9IIgyiBk4SudiPc7QrGwT)\n",
      " Call ID: call_F2q9IIgyiBk4SudiPc7QrGwT\n",
      "  Args:\n",
      "    query: common ways of performing task decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Common ways of performing task decomposition include: \n",
      "\n",
      "1. **Prompting with an LLM**: Using prompts like \"Steps for XYZ.\\n1.\" or \"What are the subgoals for achieving XYZ?\" to guide the model to break down tasks.\n",
      "2. **Task-specific instructions**: Phrasing prompts tailored to specific domains, e.g., \"Write a story outline\" for novel writing.\n",
      "3. **Human inputs**: Collaborating with humans to define the decomposition process.\n",
      "4. **LLM+P approach**: Translating problems into Planning Domain Definition Language (PDDL), outsourcing planning to an external classical planner, and translating results back into natural language.\n",
      "\n",
      "These techniques simplify tasks and enhance reasoning or planning for complex processes.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Can you look up some common ways of doing it?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d0045b",
   "metadata": {},
   "source": [
    "## Step 17: Using Pre-built ReAct Agent\n",
    "\n",
    "**LangGraph Pre-built Agents** - Leveraging ready-made agent architectures.\n",
    "\n",
    "### What is ReAct?\n",
    "**ReAct (Reasoning and Acting)** is a pattern where the LLM:\n",
    "- **Reasons**: Thinks about what it needs to do\n",
    "- **Acts**: Takes actions (calls tools)\n",
    "- **Observes**: Reviews the results\n",
    "- **Repeats**: Continues the cycle until the task is complete\n",
    "\n",
    "### `create_react_agent` vs Custom Graph:\n",
    "- **Pre-built**: Ready-to-use agent with built-in ReAct logic\n",
    "- **Simplified Setup**: Just provide LLM, tools, and optional checkpointer\n",
    "- **Proven Pattern**: Implements the well-established ReAct methodology\n",
    "- **Less Control**: Trade customization for convenience\n",
    "\n",
    "### When to Use Pre-built vs Custom:\n",
    "- **Pre-built ReAct**: For standard reasoning + tool use patterns\n",
    "- **Custom Graph**: For complex workflows with custom logic, multiple LLMs, or specialized routing\n",
    "\n",
    "### Benefits of Pre-built Agents:\n",
    "1. **Rapid Prototyping**: Get started quickly with proven patterns\n",
    "2. **Best Practices**: Incorporates community learnings and optimizations\n",
    "3. **Maintenance**: Updates and improvements come automatically\n",
    "4. **Reliability**: Thoroughly tested and validated patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc26ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e44305",
   "metadata": {},
   "source": [
    "## Step 18: Visualize the ReAct Agent Graph\n",
    "\n",
    "**ReAct Agent Architecture** - Understanding the pre-built agent structure.\n",
    "\n",
    "### Comparing Graph Structures:\n",
    "You'll notice differences between our custom graph and the ReAct agent:\n",
    "- **Additional Nodes**: ReAct has more sophisticated reasoning steps\n",
    "- **Loop Structures**: Can iterate through reasoning-action cycles\n",
    "- **Built-in Logic**: Includes decision points for continuing vs stopping\n",
    "\n",
    "### ReAct Flow Pattern:\n",
    "1. **Agent**: Analyzes the input and decides on actions\n",
    "2. **Tools**: Executes the chosen tools\n",
    "3. **Reasoning**: Evaluates results and decides next steps\n",
    "4. **Loop/Continue**: May repeat the cycle or provide final answer\n",
    "\n",
    "### Advantages of Visualization:\n",
    "- **Architecture Comparison**: See how different approaches structure workflows\n",
    "- **Complexity Understanding**: ReAct agents have more sophisticated internal logic\n",
    "- **Debugging**: Visual representation helps identify bottlenecks or issues\n",
    "- **Learning**: Understand proven patterns for building agent systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a65e6e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(agent_executor.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3140e251",
   "metadata": {},
   "source": [
    "## Step 19: Test Complex Multi-step Query with ReAct Agent\n",
    "\n",
    "**Advanced ReAct Capabilities** - Testing multi-step reasoning and multiple tool calls.\n",
    "\n",
    "### Complex Query Structure:\n",
    "The query has two distinct parts:\n",
    "1. **\"What is the standard method for Task Decomposition?\"** - Initial knowledge request\n",
    "2. **\"Once you get the answer, look up common extensions of that method.\"** - Follow-up research\n",
    "\n",
    "### ReAct Agent Advantages:\n",
    "- **Multi-step Planning**: Can break down complex requests into sequential actions\n",
    "- **Iterative Retrieval**: May call the retrieve tool multiple times\n",
    "- **Reasoning Chain**: Explicitly reasons about each step\n",
    "- **Adaptive Workflow**: Adjusts approach based on intermediate results\n",
    "\n",
    "### Expected Behavior:\n",
    "1. **First Retrieval**: Search for \"standard method for Task Decomposition\"\n",
    "2. **Reasoning**: Analyze the results and identify the standard method\n",
    "3. **Second Retrieval**: Search for \"common extensions\" of that specific method\n",
    "4. **Synthesis**: Combine information from both retrievals into a comprehensive answer\n",
    "\n",
    "### ReAct vs Custom Graph:\n",
    "- **Custom Graph**: Fixed workflow (one retrieval per query)\n",
    "- **ReAct Agent**: Dynamic workflow (multiple retrievals as needed)\n",
    "- **Reasoning Transparency**: ReAct shows its thinking process\n",
    "- **Complexity Handling**: Better suited for multi-step tasks\n",
    "\n",
    "### New Thread ID:\n",
    "Using `\"def234\"` creates a separate conversation thread, isolated from previous exchanges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "888ab68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the standard method for Task Decomposition?\n",
      "\n",
      "Once you get the answer, look up common extensions of that method.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_Sf8JPQhhHctQZaT3D43X034Y)\n",
      " Call ID: call_Sf8JPQhhHctQZaT3D43X034Y\n",
      "  Args:\n",
      "    query: What is the standard method for Task Decomposition?\n",
      "  retrieve (call_AyZlgSBcbPQMWkbWA2xPpeLO)\n",
      " Call ID: call_AyZlgSBcbPQMWkbWA2xPpeLO\n",
      "  Args:\n",
      "    query: What are common extensions of the standard method for Task Decomposition?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "### Standard Method for Task Decomposition:\n",
      "One of the standard methods for task decomposition is **Chain of Thought (CoT)**. CoT is a prompting technique where the model is instructed to think step-by-step, enabling it to break hard tasks into smaller, simpler steps and utilize more computation during problem-solving. CoT enhances performance on complex tasks and provides interpretability into the model’s reasoning by progressively decomposing tasks into manageable chunks.\n",
      "\n",
      "Another general approach includes:\n",
      "1. Using simple LLM prompts such as “Steps for XYZ:” or “What are the subgoals for achieving XYZ?”\n",
      "2. Applying task-specific instructions like “Write a story outline,” tailored to the domain.\n",
      "3. Incorporating human input for task decomposition.\n",
      "\n",
      "### Common Extensions of the Method:\n",
      "#### 1. **Tree of Thoughts (ToT)**:\n",
      "   - Extends CoT by incorporating multiple reasoning possibilities at each step.\n",
      "   - Decomposes a task into thought steps and generates multiple thoughts per step, forming a tree structure.\n",
      "   - Uses techniques like breadth-first search (BFS) or depth-first search (DFS) for exploration.\n",
      "   - Highlights reasoning paths via classifiers or majority voting.\n",
      "\n",
      "#### 2. **LLM+P**:\n",
      "   - A method that relies on external classical planners for long-horizon planning.\n",
      "   - Utilizes the Planning Domain Definition Language (PDDL):\n",
      "     - Translates the problem into PDDL format.\n",
      "     - Delegates the planning step to a classical planner for generating solutions.\n",
      "     - Converts the resulting plan back into natural language.\n",
      "   - Common in robotics where domain-specific PDDL is available.\n",
      "\n",
      "These extensions are innovative evolutions of the CoT methodology, enabling more intricate reasoning structures and external integration for improved task decomposition and planning.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"def234\"}}\n",
    "\n",
    "input_message = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "for event in agent_executor.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-module04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
