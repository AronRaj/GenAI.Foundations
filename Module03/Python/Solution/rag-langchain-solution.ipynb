{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246be15c",
   "metadata": {},
   "source": [
    "# RAG (Retrieval-Augmented Generation) with LangChain\n",
    "\n",
    "This notebook demonstrates how to build a complete RAG pipeline using LangChain and Azure OpenAI. RAG enhances language model responses by retrieving relevant context from a knowledge base before generating answers.\n",
    "\n",
    "## Overview\n",
    "We'll cover the following steps:\n",
    "1. **Environment Setup**: Load API credentials\n",
    "2. **Initialize Embeddings**: Create an embedding model for converting text to vectors\n",
    "3. **Initialize LLM**: Set up the language model for generating responses\n",
    "4. **Create Vector Store**: Initialize an in-memory vector database\n",
    "5. **Load Documents**: Fetch and parse web content\n",
    "6. **Split Documents**: Break large documents into smaller chunks\n",
    "7. **Store Embeddings**: Add document chunks to the vector store\n",
    "8. **Create RAG Chain**: Build a retrieval-augmented generation workflow\n",
    "9. **Test the System**: Query the RAG system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560722c4",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup and API Key Management\n",
    "\n",
    "This section handles the secure loading of API credentials:\n",
    "- **`load_dotenv()`**: Loads environment variables from a `.env` file if it exists in the project directory\n",
    "- **Security Best Practice**: Checks if the API key is already set in environment variables before prompting\n",
    "- **Interactive Prompt**: If the key isn't found, securely prompts the user to enter it (input will be hidden)\n",
    "- This approach works both in local development (with `.env` file) and in production (with system environment variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4740eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# Load environment variables from a .env file if present. This helps in local dev where env vars aren't set.\n",
    "load_dotenv()\n",
    "\n",
    "# Prompt for API key only if not present in environment variables after loading .env\n",
    "if not os.environ.get(\"AZURE_OPENAI_API_KEY\"):\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter your Azure OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ef5ab",
   "metadata": {},
   "source": [
    "## Step 2: Initialize the Embedding Model\n",
    "\n",
    "**Embeddings** convert text into numerical vectors (arrays of numbers) that capture semantic meaning.\n",
    "\n",
    "### What's happening here:\n",
    "- **`AzureOpenAIEmbeddings`**: Creates an embeddings client connected to Azure OpenAI\n",
    "- **`text-embedding-ada-002`**: A powerful embedding model that converts text to 1536-dimensional vectors\n",
    "- **Purpose**: These embeddings will be used to:\n",
    "  1. Convert document chunks into vectors for storage\n",
    "  2. Convert user questions into vectors for similarity search\n",
    "  \n",
    "### Why embeddings matter in RAG:\n",
    "Similar concepts will have similar vector representations, allowing us to find relevant documents by comparing vector similarity rather than exact keyword matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff693e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=\"https://aoi-ext-eus-aiml-profx-01.openai.azure.com/\",\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    api_version=\"2024-12-01-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8664fa6e",
   "metadata": {},
   "source": [
    "## Step 3: Initialize the Language Model (LLM)\n",
    "\n",
    "**Large Language Models (LLMs)** generate human-like text responses based on input prompts.\n",
    "\n",
    "### Configuration:\n",
    "- **`AzureChatOpenAI`**: Creates a chat-optimized LLM client\n",
    "- **`gpt-4o`**: The model deployment name (GPT-4 Optimized version)\n",
    "- **API Version**: Specifies the Azure OpenAI API version for compatibility\n",
    "\n",
    "### Role in RAG:\n",
    "The LLM will generate the final answer by:\n",
    "1. Receiving the user's question\n",
    "2. Receiving relevant context retrieved from the vector store\n",
    "3. Synthesizing a response that combines both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75519c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://aoi-ext-eus-aiml-profx-01.openai.azure.com/\",\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    model=\"gpt-4o\",\n",
    "    api_version=\"2024-12-01-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2866d905",
   "metadata": {},
   "source": [
    "## Step 4: Create the Vector Store\n",
    "\n",
    "**Vector Stores** (or Vector Databases) store document embeddings and enable fast similarity searches.\n",
    "\n",
    "### What is `InMemoryVectorStore`?\n",
    "- Stores vectors in RAM (not persisted to disk)\n",
    "- Fast for development and small datasets\n",
    "- Automatically uses the embeddings model we configured earlier\n",
    "\n",
    "### How it works:\n",
    "1. Documents are converted to embeddings using our embedding model\n",
    "2. Embeddings are stored along with the original text\n",
    "3. When queried, it finds the most similar vectors using cosine similarity or other distance metrics\n",
    "\n",
    "**Note**: For production use with large datasets, consider persistent vector stores like Chroma, Pinecone, or Azure AI Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee7fcbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8240952f",
   "metadata": {},
   "source": [
    "## Step 5: Load Documents from the Web\n",
    "\n",
    "**Document Loading** is the first step in building a knowledge base for RAG.\n",
    "\n",
    "### Components:\n",
    "- **`WebBaseLoader`**: Fetches HTML content from web URLs\n",
    "- **`bs4.SoupStrainer`**: Filters HTML to keep only relevant content (removes navigation, footers, etc.)\n",
    "- **Target**: A blog post about AI agents from Lilian Weng's blog\n",
    "\n",
    "### The Process:\n",
    "1. **Fetch**: Download the HTML from the specified URL\n",
    "2. **Parse**: Use BeautifulSoup to extract only the content sections\n",
    "3. **Load**: Convert to LangChain document format\n",
    "\n",
    "### Why filter HTML?\n",
    "- Reduces noise (ads, navigation, comments)\n",
    "- Focuses on the main content\n",
    "- Improves embedding quality and retrieval accuracy\n",
    "\n",
    "**Result**: A single document containing the full blog post content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2d6b4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43047\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba81730a",
   "metadata": {},
   "source": [
    "## Step 6: Preview the Document Content\n",
    "\n",
    "Let's inspect the first 500 characters of the loaded document to verify the content was extracted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcb3167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3889be67",
   "metadata": {},
   "source": [
    "## Step 7: Split Documents into Chunks\n",
    "\n",
    "**Why split documents?**\n",
    "- LLMs have context window limits (maximum input size)\n",
    "- Smaller chunks create more precise embeddings\n",
    "- Retrieval can target specific relevant sections instead of entire documents\n",
    "\n",
    "### Text Splitting Strategy:\n",
    "- **`chunk_size=1000`**: Each chunk is approximately 1000 characters\n",
    "- **`chunk_overlap=200`**: Consecutive chunks share 200 characters to maintain context continuity\n",
    "- **`add_start_index=True`**: Tracks where each chunk originated in the source document\n",
    "\n",
    "### The RecursiveCharacterTextSplitter:\n",
    "- Tries to split on natural boundaries (paragraphs, sentences, words)\n",
    "- Falls back to character-level splitting if needed\n",
    "- Preserves semantic coherence within chunks\n",
    "\n",
    "**Result**: The single large document is split into multiple smaller, manageable chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8785697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 63 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb67b97",
   "metadata": {},
   "source": [
    "## Step 8: Add Documents to Vector Store\n",
    "\n",
    "**Indexing** the documents by converting them to embeddings and storing them.\n",
    "\n",
    "### What happens in `add_documents()`:\n",
    "1. Each document chunk is sent to the embedding model\n",
    "2. The embedding model returns a vector (array of numbers) for each chunk\n",
    "3. The vector store saves both the embedding and the original text\n",
    "4. Returns unique IDs for each stored document\n",
    "\n",
    "### The Magic:\n",
    "- Documents with similar semantic meaning will have similar embedding vectors\n",
    "- When we later search with a question, the vector store can find chunks with similar embeddings\n",
    "- This enables **semantic search** (meaning-based) rather than keyword matching\n",
    "\n",
    "**Output**: A list of document IDs confirming successful storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9260a14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a361d3ea-5100-4367-a7bb-1138cc2149b8', 'f611aa8d-592f-4743-b2bd-17a844d7f3c9', 'df610398-ece3-43d3-b5c6-a3f830a97373']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2702440",
   "metadata": {},
   "source": [
    "## Step 9: Load the RAG Prompt Template\n",
    "\n",
    "**Prompt Engineering** is crucial for effective RAG systems.\n",
    "\n",
    "### What is `hub.pull()`?\n",
    "- Loads a pre-built prompt template from LangChain Hub (a repository of community prompts)\n",
    "- **`\"rlm/rag-prompt\"`**: A well-tested RAG prompt template\n",
    "\n",
    "### The RAG Prompt Structure:\n",
    "The template instructs the LLM to:\n",
    "1. Use the provided context to answer the question\n",
    "2. Say \"I don't know\" if the context doesn't contain the answer\n",
    "3. Keep answers concise and grounded in the context\n",
    "\n",
    "### Why use a template?\n",
    "- Consistent response quality\n",
    "- Reduces hallucinations (making up information)\n",
    "- Ensures the LLM leverages the retrieved context effectively\n",
    "\n",
    "**Preview**: We can see how the template formats the context and question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c80fa721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# N.B. for non-US LangSmith endpoints, you may need to specify\n",
    "# api_url=\"https://api.smith.langchain.com\" in hub.pull.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a983b",
   "metadata": {},
   "source": [
    "## Step 10: Define the State Schema\n",
    "\n",
    "**State Management** for our RAG workflow using TypedDict.\n",
    "\n",
    "### What is State?\n",
    "A structured data container that flows through our RAG pipeline:\n",
    "- **`question`**: The user's input query (str)\n",
    "- **`context`**: Retrieved documents relevant to the question (List[Document])\n",
    "- **`answer`**: The LLM's generated response (str)\n",
    "\n",
    "### Why define State?\n",
    "- **Type Safety**: Ensures each step receives and returns the correct data types\n",
    "- **Clarity**: Makes the data flow explicit and easier to debug\n",
    "- **LangGraph Integration**: LangGraph uses this schema to manage state between nodes\n",
    "\n",
    "This will be used in the next steps to build a stateful workflow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d9e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fec75b",
   "metadata": {},
   "source": [
    "## Step 11: Define RAG Workflow Functions\n",
    "\n",
    "**The two core functions of the RAG pipeline:**\n",
    "\n",
    "### 1. `retrieve(state)` - Retrieval Step\n",
    "- **Input**: Takes the current state (containing the question)\n",
    "- **Process**: \n",
    "  - Converts the question to an embedding\n",
    "  - Searches the vector store for similar document chunks\n",
    "  - Uses cosine similarity to find the most relevant documents\n",
    "- **Output**: Updates state with `context` (list of retrieved documents)\n",
    "\n",
    "### 2. `generate(state)` - Generation Step\n",
    "- **Input**: Takes the state (containing question and context)\n",
    "- **Process**:\n",
    "  - Combines all retrieved document content into a single string\n",
    "  - Formats the prompt with the question and context\n",
    "  - Sends to the LLM for answer generation\n",
    "- **Output**: Updates state with `answer` (the LLM's response)\n",
    "\n",
    "### The RAG Flow:\n",
    "**Question → Retrieve Context → Generate Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74d2ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c2818",
   "metadata": {},
   "source": [
    "## Step 12: Build the RAG Graph with LangGraph\n",
    "\n",
    "**LangGraph** creates a stateful, directed workflow for our RAG pipeline.\n",
    "\n",
    "### Graph Construction:\n",
    "1. **`StateGraph(State)`**: Initialize a graph that manages our State schema\n",
    "2. **`add_sequence([retrieve, generate])`**: Chain the functions sequentially\n",
    "   - First: `retrieve` gets relevant documents\n",
    "   - Then: `generate` creates the answer\n",
    "3. **`add_edge(START, \"retrieve\")`**: Define the entry point (start with retrieval)\n",
    "4. **`compile()`**: Build the executable graph\n",
    "\n",
    "### Benefits of LangGraph:\n",
    "- **State Persistence**: Automatically passes state between nodes\n",
    "- **Debugging**: Can visualize and trace the workflow\n",
    "- **Flexibility**: Easy to add steps (e.g., query rewriting, re-ranking)\n",
    "- **Streaming**: Can stream intermediate results\n",
    "\n",
    "**Result**: A compiled graph ready to process questions through the RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d3634d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e75be48",
   "metadata": {},
   "source": [
    "## Step 13: Visualize the Workflow Graph\n",
    "\n",
    "**Visual Representation** of our RAG pipeline using Mermaid diagrams.\n",
    "\n",
    "### What to Expect:\n",
    "The diagram will show:\n",
    "- **Nodes**: Each step in the workflow (`retrieve`, `generate`)\n",
    "- **Edges**: The flow of data between steps\n",
    "- **Entry Point**: Where the workflow starts\n",
    "- **End Point**: Where it completes\n",
    "\n",
    "This visualization helps understand the execution flow and is useful for:\n",
    "- Debugging complex workflows\n",
    "- Documentation and team communication\n",
    "- Identifying optimization opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23b83866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf536f1",
   "metadata": {},
   "source": [
    "## Step 14: Test the RAG System\n",
    "\n",
    "**First Query** - Testing the complete pipeline with a sample question.\n",
    "\n",
    "### Execution Flow:\n",
    "1. **Input**: `{\"question\": \"What is Task Decomposition?\"}`\n",
    "2. **Retrieve Step**: \n",
    "   - Converts question to embedding\n",
    "   - Finds most similar document chunks from the blog post\n",
    "   - Returns relevant context about task decomposition\n",
    "3. **Generate Step**:\n",
    "   - Formats prompt with question + retrieved context\n",
    "   - LLM generates answer based on the context\n",
    "4. **Output**: Complete result with context and answer\n",
    "\n",
    "### Expected Result:\n",
    "- **Context**: The actual document chunks retrieved from the vector store\n",
    "- **Answer**: A concise explanation of Task Decomposition based on the blog content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb3611d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(id='df610398-ece3-43d3-b5c6-a3f830a97373', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'), Document(id='9b9d67d8-3ccf-47b2-93d8-3e015f690bc8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'), Document(id='80754bdf-90c9-4ab0-a545-b361e7853d36', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='28cae412-f5fe-45ea-8bbf-a503b40b60da', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#')]\n",
      "\n",
      "\n",
      "Answer: Task decomposition is the process of breaking down a complex task into smaller, simpler steps or subgoals to make it more manageable. Techniques like Chain of Thought (CoT) and Tree of Thoughts (ToT) employ structured reasoning to facilitate decomposition, while tools like LLM+P use external planners for long-horizon tasks. It can be done using prompts, task-specific instructions, or human inputs.\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "\n",
    "print(f\"Context: {result['context']}\\n\\n\")\n",
    "print(f\"Answer: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace95300",
   "metadata": {},
   "source": [
    "## Step 15: Stream the Workflow Updates\n",
    "\n",
    "**Streaming Mode: Updates** - Observe each step of the workflow as it executes.\n",
    "\n",
    "### What is `stream_mode=\"updates\"`?\n",
    "- Shows the state changes after each node completes\n",
    "- Provides visibility into the pipeline execution\n",
    "- Useful for debugging and understanding the workflow\n",
    "\n",
    "### Output Format:\n",
    "You'll see two updates:\n",
    "1. **After `retrieve`**: Shows the retrieved context documents\n",
    "2. **After `generate`**: Shows the generated answer\n",
    "\n",
    "This is helpful for:\n",
    "- **Debugging**: Identify which step is slow or failing\n",
    "- **Validation**: Verify the right documents are being retrieved\n",
    "- **Monitoring**: Track progress in real-time applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccd27f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'context': [Document(id='df610398-ece3-43d3-b5c6-a3f830a97373', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'), Document(id='9b9d67d8-3ccf-47b2-93d8-3e015f690bc8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'), Document(id='80754bdf-90c9-4ab0-a545-b361e7853d36', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='28cae412-f5fe-45ea-8bbf-a503b40b60da', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'Task decomposition is the process of breaking down a complex task into smaller, manageable steps or subgoals. It can be facilitated through techniques like Chain of Thought (CoT) prompting or external methods like classical planning via Planning Domain Definition Language (PDDL). This approach helps enhance problem-solving by structuring tasks into clearer, more actionable units.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f75cd5",
   "metadata": {},
   "source": [
    "## Step 16: Stream LLM Messages (Token-by-Token)\n",
    "\n",
    "**Streaming Mode: Messages** - Watch the LLM generate the response in real-time.\n",
    "\n",
    "### What is `stream_mode=\"messages\"`?\n",
    "- Streams individual messages/tokens as they're generated by the LLM\n",
    "- Shows the answer being constructed incrementally\n",
    "- Similar to how ChatGPT displays responses word-by-word\n",
    "\n",
    "### Use Cases:\n",
    "- **User Experience**: Display progressive responses in chat interfaces\n",
    "- **Real-time Feedback**: Users see that processing is happening\n",
    "- **Early Termination**: Can stop generation if the answer is sufficient\n",
    "\n",
    "### Output:\n",
    "- Each token/chunk of the LLM response is printed as it's generated\n",
    "- The `|` separator shows where each chunk ends\n",
    "- This demonstrates the streaming capability for production applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2482e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||Task| decomposition| involves| breaking| down| complex| tasks| into| smaller|,| simpler|,| and| manageable| subt|asks|.| Techniques| like| Chain| of| Thought| (|Co|T|)| and| Tree| of| Thoughts| (|To|T|)| enhance| this| process| by| encouraging| step|-by|-step| reasoning| or| exploring| multiple| possibilities|.| De|composition| can| be| done| with| L|LM| prompts|,| human| inputs|,| task|-specific| instructions|,| or| external| planning| tools| like| P|DDL| for| detailed| planning|.|||"
     ]
    }
   ],
   "source": [
    "for message, metadata in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-module03",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
