{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3389586",
   "metadata": {},
   "source": [
    "# Semantic Search with LangChain and Azure OpenAI\n",
    "\n",
    "This notebook demonstrates how to build a semantic search system using vector embeddings. Unlike traditional keyword-based search, semantic search understands the **meaning** of queries and documents, enabling more intelligent and context-aware information retrieval.\n",
    "\n",
    "## What is Semantic Search?\n",
    "\n",
    "Semantic search uses machine learning models to convert text into numerical vectors (embeddings) that capture semantic meaning. Documents with similar meanings will have similar vector representations, allowing us to find relevant information based on conceptual similarity rather than just keyword matching.\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. **Load Documents**: Import PDF documents into processable format\n",
    "2. **Split Text**: Divide large documents into smaller, focused chunks\n",
    "3. **Generate Embeddings**: Convert text chunks into vector representations\n",
    "4. **Store Vectors**: Index embeddings in a vector database\n",
    "5. **Search**: Query the system to find semantically similar content\n",
    "\n",
    "Let's dive into each step!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f7936",
   "metadata": {},
   "source": [
    "## Step 1: Loading Documents\n",
    "\n",
    "**Document loading** is the foundation of any information retrieval system. We'll load a PDF file containing Nike's 10-K financial report from 2023.\n",
    "\n",
    "### Why PDFs?\n",
    "- Common format for reports, papers, and documentation\n",
    "- Contains structured and unstructured data\n",
    "- Requires specialized parsing to extract text accurately\n",
    "\n",
    "### Your Task:\n",
    "Import the `PyPDFLoader` class from LangChain and load the PDF document located at `../../data/nke-10k-2023.pdf`\n",
    "\n",
    "**Steps:**\n",
    "1. Import `PyPDFLoader` from `langchain_community.document_loaders`\n",
    "2. Create a variable `file_path` with the value `\"../../data/nke-10k-2023.pdf\"`\n",
    "3. Create a loader instance: `loader = PyPDFLoader(file_path)`\n",
    "4. Call `load()` method to extract all pages: `docs = loader.load()`\n",
    "5. Print the number of documents loaded: `print(len(docs))`\n",
    "\n",
    "**Expected Output:** A number representing the total pages in the PDF (should be around 110-120 pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950212a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import PyPDFLoader from langchain_community.document_loaders\n",
    "\n",
    "\n",
    "# TODO: Set file_path variable to \"../../data/nke-10k-2023.pdf\"\n",
    "\n",
    "\n",
    "# TODO: Create a PyPDFLoader instance\n",
    "\n",
    "\n",
    "# TODO: Load the documents using the load() method\n",
    "\n",
    "\n",
    "# TODO: Print the number of documents loaded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf382dff",
   "metadata": {},
   "source": [
    "### Understanding Document Structure\n",
    "\n",
    "Each `Document` object created by `PyPDFLoader` contains:\n",
    "- **`page_content`**: The string content of the page (all text extracted)\n",
    "- **`metadata`**: A dictionary with:\n",
    "  - `source`: File path to the original PDF\n",
    "  - `page`: Page number (0-indexed)\n",
    "\n",
    "### Your Task:\n",
    "Inspect the first document to understand its structure.\n",
    "\n",
    "**Steps:**\n",
    "1. Print the first 200 characters of the first document's content: `print(f\"{docs[0].page_content[:200]}\\\\n\")`\n",
    "2. Print the metadata of the first document: `print(docs[0].metadata)`\n",
    "\n",
    "**Expected Output:** \n",
    "- A preview of text from the first page\n",
    "- Metadata showing the source file path and page number (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3b208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the first 200 characters of the first document's page_content\n",
    "\n",
    "\n",
    "# TODO: Print the metadata of the first document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e7ddc",
   "metadata": {},
   "source": [
    "## Step 2: Document Splitting Strategy\n",
    "\n",
    "### Why Split Documents?\n",
    "\n",
    "**Problem**: A full PDF page is often too large and contains multiple topics.\n",
    "- Mixing different concepts in one chunk dilutes the semantic meaning\n",
    "- Large chunks make it harder to pinpoint specific information\n",
    "- Retrieval accuracy suffers when relevant details are buried in irrelevant context\n",
    "\n",
    "**Solution**: Split documents into smaller, focused chunks.\n",
    "\n",
    "### Your Task:\n",
    "Use `RecursiveCharacterTextSplitter` to split documents into manageable chunks.\n",
    "\n",
    "**Steps:**\n",
    "1. Import `RecursiveCharacterTextSplitter` from `langchain_text_splitters`\n",
    "2. Create a text splitter with these parameters:\n",
    "   - `chunk_size=1000` (target 1000 characters per chunk)\n",
    "   - `chunk_overlap=200` (overlap consecutive chunks by 200 characters)\n",
    "   - `add_start_index=True` (track original position)\n",
    "3. Split the documents: `all_splits = text_splitter.split_documents(docs)`\n",
    "4. Print the number of chunks created: `len(all_splits)`\n",
    "\n",
    "**Why \"Recursive\"?** The splitter tries to split on natural boundaries in this order:\n",
    "1. Paragraphs (double newlines)\n",
    "2. Sentences (single newlines)\n",
    "3. Words (spaces)\n",
    "4. Characters (as last resort)\n",
    "\n",
    "**Expected Output:** A number much larger than the original page count (typically 500-800 chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3585421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import RecursiveCharacterTextSplitter from langchain_text_splitters\n",
    "\n",
    "\n",
    "# TODO: Create a RecursiveCharacterTextSplitter with chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    "\n",
    "\n",
    "# TODO: Split the documents using split_documents() method\n",
    "\n",
    "\n",
    "# TODO: Print the number of chunks created\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d5461",
   "metadata": {},
   "source": [
    "## Step 3: Configure Azure OpenAI Embeddings\n",
    "\n",
    "**Embeddings** are the heart of semantic search - they convert text into numerical vectors that capture meaning.\n",
    "\n",
    "### What are Embeddings?\n",
    "- **Input**: Text string (query or document)\n",
    "- **Output**: Vector of numbers (e.g., 1536 dimensions for text-embedding-ada-002)\n",
    "- **Property**: Similar meanings → Similar vectors\n",
    "\n",
    "### Your Task:\n",
    "Set up Azure OpenAI embeddings to convert text into vectors.\n",
    "\n",
    "**Steps:**\n",
    "1. Import necessary modules:\n",
    "   - `getpass` and `os` for secure API key handling\n",
    "   - `AzureOpenAIEmbeddings` from `langchain_openai`\n",
    "2. Check if `AZURE_OPENAI_API_KEY` exists in environment variables\n",
    "3. If not, prompt the user to enter it securely using `getpass.getpass()`\n",
    "4. Create an `AzureOpenAIEmbeddings` instance with:\n",
    "   - `azure_endpoint=\"https://aoi-ext-eus-aiml-profx-01.openai.azure.com/\"`\n",
    "   - `api_key=os.environ[\"AZURE_OPENAI_API_KEY\"]`\n",
    "   - `model=\"text-embedding-ada-002\"`\n",
    "   - `api_version=\"2024-12-01-preview\"`\n",
    "\n",
    "**Security Note:** Never hardcode API keys! Always use environment variables or secure input methods.\n",
    "\n",
    "**Expected Output:** No output, but the `embeddings` object will be ready to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543374d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import getpass and os modules\n",
    "\n",
    "\n",
    "# TODO: Check if AZURE_OPENAI_API_KEY exists in environment, if not, prompt for it\n",
    "\n",
    "\n",
    "# TODO: Import AzureOpenAIEmbeddings from langchain_openai\n",
    "\n",
    "\n",
    "# TODO: Create an AzureOpenAIEmbeddings instance with the required parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520bfc6a",
   "metadata": {},
   "source": [
    "### Test the Embeddings Model\n",
    "\n",
    "Let's verify the embeddings are working by converting two document chunks into vectors.\n",
    "\n",
    "### Your Task:\n",
    "Generate embeddings for the first two document chunks and verify they work correctly.\n",
    "\n",
    "**Steps:**\n",
    "1. Use `embeddings.embed_query()` to convert the first chunk's content to a vector: `vector_1 = embeddings.embed_query(all_splits[0].page_content)`\n",
    "2. Do the same for the second chunk: `vector_2 = embeddings.embed_query(all_splits[1].page_content)`\n",
    "3. Verify both vectors have the same length using an assertion: `assert len(vector_1) == len(vector_2)`\n",
    "4. Print the vector length: `print(f\"Generated vectors of length {len(vector_1)}\\\\n\")`\n",
    "5. Print the first 10 values of vector_1: `print(vector_1[:10])`\n",
    "\n",
    "**Expected Output:** \n",
    "- Message showing vectors of length 1536\n",
    "- A list of 10 floating-point numbers representing the first dimensions of the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate embedding vector for the first chunk\n",
    "\n",
    "\n",
    "# TODO: Generate embedding vector for the second chunk\n",
    "\n",
    "\n",
    "# TODO: Assert that both vectors have the same length\n",
    "\n",
    "\n",
    "# TODO: Print the vector length\n",
    "\n",
    "\n",
    "# TODO: Print the first 10 values of vector_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c7c55",
   "metadata": {},
   "source": [
    "## Step 4: Initialize the Vector Store\n",
    "\n",
    "**Vector Stores** are specialized databases optimized for storing and searching high-dimensional vectors.\n",
    "\n",
    "### What is InMemoryVectorStore?\n",
    "- **Type**: In-memory storage (not persisted to disk)\n",
    "- **Speed**: Fast for development and prototyping\n",
    "- **Scope**: Data exists only during the session\n",
    "- **Best For**: Testing, small datasets, demonstrations\n",
    "\n",
    "### Your Task:\n",
    "Create an in-memory vector store to hold our document embeddings.\n",
    "\n",
    "**Steps:**\n",
    "1. Import `InMemoryVectorStore` from `langchain_core.vectorstores`\n",
    "2. Create a vector store instance: `vector_store = InMemoryVectorStore(embeddings)`\n",
    "\n",
    "**Production Alternatives:**\n",
    "For production use with large datasets or persistence requirements, consider:\n",
    "- **Chroma**: Local, persistent vector database\n",
    "- **Pinecone**: Managed cloud vector database\n",
    "- **Azure AI Search**: Azure's vector search service\n",
    "- **Weaviate**: Open-source vector database\n",
    "\n",
    "**Expected Output:** No output, but the vector store is now ready to store embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa95ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import InMemoryVectorStore from langchain_core.vectorstores\n",
    "\n",
    "\n",
    "# TODO: Create an InMemoryVectorStore instance with the embeddings object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4f1d50",
   "metadata": {},
   "source": [
    "## Step 5: Index Documents in the Vector Store\n",
    "\n",
    "**Indexing** is the process of storing documents with their embeddings for later retrieval.\n",
    "\n",
    "### What happens during indexing:\n",
    "1. **For each document chunk**:\n",
    "   - Send the text to the embeddings model\n",
    "   - Receive back a 1536-dimensional vector\n",
    "   - Store both the text and vector in the database\n",
    "   - Generate a unique ID for tracking\n",
    "\n",
    "2. **Build the index**:\n",
    "   - Organize vectors for efficient similarity search\n",
    "   - Create data structures for fast nearest-neighbor lookup\n",
    "\n",
    "### Your Task:\n",
    "Add all document chunks to the vector store.\n",
    "\n",
    "**Steps:**\n",
    "1. Call `vector_store.add_documents()` with the `all_splits` list: `ids = vector_store.add_documents(documents=all_splits)`\n",
    "2. The method returns a list of unique IDs for each stored document\n",
    "\n",
    "**Performance Note:**\n",
    "This operation makes API calls to Azure OpenAI for each chunk, so it may take some time depending on:\n",
    "- Number of chunks\n",
    "- API rate limits\n",
    "- Network latency\n",
    "\n",
    "**Expected Output:** The indexing will complete (may take 1-2 minutes), and you'll have a searchable knowledge base!\n",
    "\n",
    "**⚠️ Note:** This step may take a while to complete. Be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cf44a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add all document chunks to the vector store using add_documents()\n",
    "# This will take some time as it needs to generate embeddings for all chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71141dc0",
   "metadata": {},
   "source": [
    "## Step 6: Perform Your First Similarity Search\n",
    "\n",
    "**Semantic search in action!** Let's query the system to find information about Nike's distribution centers.\n",
    "\n",
    "### How Similarity Search Works:\n",
    "1. **Convert Query**: The question is converted to an embedding vector\n",
    "2. **Compare Vectors**: The system compares the query vector to all stored document vectors\n",
    "3. **Calculate Similarity**: Uses cosine similarity or distance metrics\n",
    "4. **Rank Results**: Returns the most similar documents\n",
    "5. **Default**: Returns top 4 most relevant chunks\n",
    "\n",
    "### Your Task:\n",
    "Search for information about Nike's distribution centers.\n",
    "\n",
    "**Steps:**\n",
    "1. Call `vector_store.similarity_search()` with the query: `\"How many distribution centers does Nike have in the US?\"`\n",
    "2. Store the results: `results = vector_store.similarity_search(\"How many distribution centers does Nike have in the US?\")`\n",
    "3. Print the first result: `print(results[0])`\n",
    "\n",
    "**Why this is powerful:**\n",
    "- No exact keyword matching required\n",
    "- Understands \"distribution centers\" relates to \"facilities,\" \"warehouses,\" etc.\n",
    "- Captures semantic intent of the question\n",
    "- Finds relevant content even with different wording\n",
    "\n",
    "**Expected Output:** The most relevant document chunk containing information about Nike's distribution infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdcc9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform a similarity search with the query about distribution centers\n",
    "\n",
    "\n",
    "# TODO: Print the first result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e115c",
   "metadata": {},
   "source": [
    "## Step 7: Async Similarity Search\n",
    "\n",
    "**Asynchronous search** enables non-blocking operations, crucial for production applications.\n",
    "\n",
    "### What is Async?\n",
    "- **Traditional (Sync)**: Code waits for search to complete before continuing\n",
    "- **Async**: Search runs in background, allowing other operations simultaneously\n",
    "- **Use Cases**: Web applications, API endpoints, concurrent queries\n",
    "\n",
    "### Your Task:\n",
    "Perform an asynchronous similarity search.\n",
    "\n",
    "**Steps:**\n",
    "1. Use `await` with `vector_store.asimilarity_search()` to search for: `\"When was Nike incorporated?\"`\n",
    "2. Store the results: `results = await vector_store.asimilarity_search(\"When was Nike incorporated?\")`\n",
    "3. Print the first result: `print(results[0])`\n",
    "\n",
    "**Benefits of Async Search:**\n",
    "- **Responsiveness**: UI remains interactive during search\n",
    "- **Scalability**: Handle multiple search requests concurrently\n",
    "- **Performance**: Better resource utilization in I/O-bound operations\n",
    "\n",
    "**Note**: In Jupyter notebooks, async functions work seamlessly with `await`. In regular Python scripts, you'd need to use `asyncio.run()` or an event loop.\n",
    "\n",
    "**Expected Output:** Document chunk containing information about Nike's founding/incorporation date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbedf282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform an async similarity search about Nike's incorporation\n",
    "\n",
    "\n",
    "# TODO: Print the first result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879be44e",
   "metadata": {},
   "source": [
    "## Step 8: Similarity Search with Confidence Scores\n",
    "\n",
    "**Understanding search quality** by examining similarity scores alongside results.\n",
    "\n",
    "### What are Similarity Scores?\n",
    "- **Purpose**: Quantify how well each result matches the query\n",
    "- **Range**: Depends on the distance metric used\n",
    "- **Interpretation**: Lower scores = higher similarity (for distance metrics)\n",
    "\n",
    "### Your Task:\n",
    "Search with scores to understand result quality.\n",
    "\n",
    "**Steps:**\n",
    "1. Use `vector_store.similarity_search_with_score()` to search for: `\"What was Nike's revenue in 2023?\"`\n",
    "2. Store the results: `results = vector_store.similarity_search_with_score(\"What was Nike's revenue in 2023?\")`\n",
    "3. Extract the first document and score: `doc, score = results[0]`\n",
    "4. Print the score: `print(f\"Score: {score}\\\\n\")`\n",
    "5. Print the document: `print(doc)`\n",
    "\n",
    "### Why Scores Matter:\n",
    "- **Filtering**: Set thresholds to exclude low-quality matches\n",
    "- **Ranking**: Sort results by relevance\n",
    "- **Confidence**: Determine if results are trustworthy\n",
    "- **Debugging**: Identify when queries aren't matching well\n",
    "\n",
    "**Note:** Providers implement different scores. The score here is a distance metric that varies inversely with similarity (lower = more similar).\n",
    "\n",
    "**Expected Output:** \n",
    "- A numerical score indicating match quality\n",
    "- The most relevant document chunk about Nike's revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform a similarity search with scores for Nike's revenue query\n",
    "\n",
    "\n",
    "# TODO: Extract the first document and its score from the results\n",
    "\n",
    "\n",
    "# TODO: Print the score\n",
    "\n",
    "\n",
    "# TODO: Print the document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861bd69d",
   "metadata": {},
   "source": [
    "## Step 9: Search with Pre-computed Embeddings\n",
    "\n",
    "**Advanced technique**: Search using vectors directly instead of text queries.\n",
    "\n",
    "### Why Use Pre-computed Embeddings?\n",
    "\n",
    "**Scenario 1 - Performance Optimization:**\n",
    "- Generate query embedding once\n",
    "- Reuse it for multiple searches\n",
    "- Reduces API calls and latency\n",
    "\n",
    "**Scenario 2 - Advanced Workflows:**\n",
    "- Search with modified/combined embeddings\n",
    "- Implement custom similarity logic\n",
    "- Build hybrid search systems\n",
    "\n",
    "**Scenario 3 - Cross-modal Search:**\n",
    "- Search documents using image embeddings\n",
    "- Find similar concepts across different data types\n",
    "\n",
    "### Your Task:\n",
    "Perform a two-step search using pre-computed embeddings.\n",
    "\n",
    "**Steps:**\n",
    "1. Generate an embedding for the query: `embedding = embeddings.embed_query(\"How were Nike's margins impacted in 2023?\")`\n",
    "2. Search using the vector: `results = vector_store.similarity_search_by_vector(embedding)`\n",
    "3. Print the first result: `print(results[0])`\n",
    "\n",
    "**Use Case:**\n",
    "This pattern is especially useful when:\n",
    "- Building search APIs (cache embeddings)\n",
    "- Implementing recommendation systems\n",
    "- Creating multi-step search pipelines\n",
    "\n",
    "**Expected Output:** Same quality results as text-based search, but with more control over the embedding process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ee3ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate an embedding for the query about Nike's margins\n",
    "\n",
    "\n",
    "# TODO: Perform a similarity search using the pre-computed embedding vector\n",
    "\n",
    "\n",
    "# TODO: Print the first result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ee6338",
   "metadata": {},
   "source": [
    "## Congratulations! 🎉\n",
    "\n",
    "You've successfully built a semantic search system using LangChain and Azure OpenAI! \n",
    "\n",
    "### What You've Learned:\n",
    "- ✅ Load and parse PDF documents\n",
    "- ✅ Split large documents into meaningful chunks\n",
    "- ✅ Generate embeddings using Azure OpenAI\n",
    "- ✅ Store embeddings in a vector database\n",
    "- ✅ Perform semantic similarity searches\n",
    "- ✅ Use both synchronous and asynchronous search methods\n",
    "- ✅ Understand similarity scores and their importance\n",
    "- ✅ Work with pre-computed embeddings for advanced use cases\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different chunk sizes and overlap values\n",
    "- Try different queries to test the semantic understanding\n",
    "- Explore other vector stores like Chroma or Pinecone\n",
    "- Move on to the RAG notebook to build a complete question-answering system!\n",
    "\n",
    "### Challenge Exercises:\n",
    "1. Try searching for \"Nike's sustainability efforts\" and see what you find\n",
    "2. Experiment with chunk_size values (500, 1500, 2000) and compare results\n",
    "3. Search for the same query using all three methods: `similarity_search()`, `asimilarity_search()`, and `similarity_search_by_vector()`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
